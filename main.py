import os
import arxiv
import openai
from notion_client import Client
import datetime
from pytz import timezone

# 1. ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
NOTION_TOKEN = os.environ["NOTION_TOKEN"]
DATABASE_ID = os.environ["DATABASE_ID"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
GITHUB_USER = "Choihyunseok1"
GITHUB_REPO = "Paper2Audio"

notion = Client(auth=NOTION_TOKEN)
client = openai.OpenAI(api_key=OPENAI_API_KEY)

def run_bot():
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    base_path = os.path.dirname(os.path.abspath(__file__))
    audio_dir = os.path.join(base_path, "audio")
    os.makedirs(audio_dir, exist_ok=True)

    # 2. ì‹œê°„ëŒ€ ì„¤ì • (ì„œìš¸ ì‹œê°„ ê¸°ì¤€ ì–´ì œ 18:00 ~ í˜„ì¬)
    seoul_tz = timezone('Asia/Seoul')
    now = datetime.datetime.now(seoul_tz)
    yesterday_6pm = (now - datetime.timedelta(days=1)).replace(hour=18, minute=0, second=0, microsecond=0)

    # 3. arXiv ë…¼ë¬¸ ê²€ìƒ‰ (ìµœê·¼ ë“±ë¡ ìˆœìœ¼ë¡œ 10ê°œê¹Œì§€ ê°€ì ¸ì™€ì„œ ì‹œê°„ í•„í„°ë§)
    search = arxiv.Search(
        query="cat:cs.CV",
        max_results=10,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )

    valid_papers = []
    for p in search.results():
        # arXivì˜ published ì‹œê°„ì€ UTC ê¸°ì¤€ì´ë¯€ë¡œ ì„œìš¸ ì‹œê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
        p_date = p.published.astimezone(seoul_tz)
        if p_date > yesterday_6pm:
            valid_papers.append(p)

    if not valid_papers:
        print("í•´ë‹¹ ì‹œê°„ëŒ€ì— ìƒˆë¡œ ì˜¬ë¼ì˜¨ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4. ëª¨ë“  ë…¼ë¬¸ì„ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ í†µí•©
    papers_info = ""
    paper_titles_list = []
    for i, p in enumerate(valid_papers):
        papers_info += f"ë…¼ë¬¸ {i+1} ì œëª©: {p.title}\nì´ˆë¡: {p.summary}\n\n"
        paper_titles_list.append(p.title)

    combined_prompt = f"""
    ì•„ë˜ëŠ” ì–´ì œ ì €ë…ë¶€í„° ì˜¤ëŠ˜ ìƒˆë²½ ì‚¬ì´ì— ìƒˆë¡œ ë°œí‘œëœ {len(valid_papers)}ê°œì˜ ì»´í“¨í„° ë¹„ì „ ë…¼ë¬¸ì…ë‹ˆë‹¤.
    
    {papers_info}

    ìœ„ ë…¼ë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    1. [ìš”ì•½]
    - ë…¸ì…˜ ê¸°ë¡ìš© í•µì‹¬ ìš”ì•½.
    - ê° ë…¼ë¬¸ë³„ë¡œ ì œëª©ì„ ì–¸ê¸‰í•˜ê³ , '-í•¨', '-ì„' í˜•íƒœì˜ ì§§ì€ ìš”ì•½ì²´ë¡œ 2~3ì¤„ì”© ì‘ì„±.
    - ê° ë…¼ë¬¸ ìš”ì•½ ì‹œì‘ì‹œ '1. (ë…¼ë¬¸ì œëª©)' ì‹ìœ¼ë¡œ ì•ì— ë²ˆí˜¸ë§Œ ë¶™ì—¬ ì§„í–‰í•  ê²ƒ
    - ë…¼ë¬¸ë“¤ ì‚¬ì´ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•  ê²ƒ.

    2. [ëŒ€ë³¸] ì‘ì„± ê°€ì´ë“œë¼ì¸:
    - í˜•ì‹: ë¼ë””ì˜¤ ë°©ì†¡ 'ëª¨ë‹ Computer Vision AI ë¸Œë¦¬í•‘' ìŠ¤í¬ë¦½íŠ¸.
    - êµ¬ì„±: [ë„ì…ë¶€] - [ë³¸ë¬¸: ë…¼ë¬¸ë³„ ì—°ê²°] - [ë§ºìŒë§]ì˜ ë‹¨ì¼ ì—í”¼ì†Œë“œ êµ¬ì¡°.
    - ë„ì…ë¶€: "ì•ˆë…•í•˜ì„¸ìš”, IRCV ë©ì‹¤ì˜ ìˆ˜ì„ ì—°êµ¬ ë¹„ì„œì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‚´í´ë³¼ ì»´í“¨í„° ë¹„ì „ ì‹ ê·œ ë…¼ë¬¸ì€ ì´ {len(valid_papers)}ê±´ì…ë‹ˆë‹¤."ë¡œ ì‹œì‘í•  ê²ƒ.
    - í˜¸í¡ ì¡°ì ˆ: 
        * ë¬¸ì¥ ì‚¬ì´ì—ëŠ” ì¶©ë¶„í•œ ì‰¼í‘œ(,)ë¥¼ ì‚¬ìš©í•´ ì•„ë‚˜ìš´ì„œê°€ ìˆ¨ì„ ê³ ë¥´ëŠ” ì§€ì ì„ í‘œì‹œí•  ê²ƒ.
        * ì¤‘ìš”í•œ ê°•ì¡°ì  ì•ë’¤ì—ëŠ” ë§ˆì¹¨í‘œ(.)ë¥¼ ì°ì–´ í™•ì‹¤íˆ ëŠì–´ ì½ê²Œ í•  ê²ƒ.
    - ì–¸ì–´ ì²˜ë¦¬:
        * ë…¼ë¬¸ì˜ ê³µì‹ ì œëª©ì€ ë°˜ë“œì‹œ **ì˜ë¬¸ ì›ë¬¸**ìœ¼ë¡œ í‘œê¸°í•  ê²ƒ.
        * ë‹¨, ì˜ë¬¸ ì œëª© ë°”ë¡œ ë’¤ì— ê´„í˜¸ë¡œ **[í•œê¸€ ë°œìŒ]**ì„ ë°˜ë“œì‹œ ì ì„ ê²ƒ. (ì˜ˆ: ResNet -> ë ˆì¦ˆë„·)
        * ëª¨ë“  ê¸°ìˆ  ì•½ì–´(CNN, ViT, SOTA ë“±)ëŠ” 100% í•œê¸€ ë°œìŒìœ¼ë¡œë§Œ í‘œê¸°í•  ê²ƒ. (ì˜ˆ: ì‹œì—”ì—”, ë¹„ì•„ì´í‹°, ì†Œíƒ€)
    - í†¤ì•¤ë§¤ë„ˆ:
        * í…ìŠ¤íŠ¸ë¥¼ ì½ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë™ë£Œ ì—°êµ¬ìì—ê²Œ 'ì„¤ëª…'í•´ì£¼ëŠ” ë“¯í•œ ì°¨ë¶„í•˜ê³  ë‹¤ì •í•œ ì–´ì¡°.
        * "ì´ ë…¼ë¬¸ì€ ~ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤" ë³´ë‹¤ëŠ” "ì´ ì—°êµ¬ì—ì„œëŠ” ~ë¼ëŠ” í¥ë¯¸ë¡œìš´ ì ‘ê·¼ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤" ê°™ì€ êµ¬ì–´ì²´ ì‚¬ìš©.
    - ë§ˆë¬´ë¦¬: "ì˜¤ëŠ˜ì˜ ë¸Œë¦¬í•‘ì´ ì—¬ëŸ¬ë¶„ì˜ ì—°êµ¬ì— ì˜ê°ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ì´ìƒ, IRCV ì—°êµ¬ ë¹„ì„œì˜€ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."

    ì¶œë ¥ í˜•ì‹:
    [ìš”ì•½]
    (í†µí•© ìš”ì•½ ë‚´ìš©)

    [ëŒ€ë³¸]
    (í†µí•© ë¼ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©)
    """

    # 5. GPT-4oì—ê²Œ í†µí•© ìš”ì²­
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content":
                   "ë„ˆëŠ” IRCV(ì•„ì´ì•Œì”¨ë¸Œì´) ë©ì‹¤ì˜ ìˆ˜ì„ ì—°êµ¬ ë¹„ì„œì´ì, AI ì „ë¬¸ ë¼ë””ì˜¤ ì§„í–‰ìì•¼. "
                   "ë³µì¡í•œ ê¸°ìˆ  ê°œë…ì„ ì°¨ë¶„í•˜ê³  ëª…ë£Œí•œ í•œêµ­ì–´ë¡œ ì „ë‹¬í•˜ë©°, "
                   "íŠ¹íˆ TTSê°€ ì½ê¸° ì¢‹ê²Œ ë¬¸ì¥ ë¶€í˜¸ì™€ í•œê¸€ ë°œìŒ í‘œê¸°ë¥¼ ì™„ë²½í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                  {"role": "user", "content": combined_prompt}]
    )
    full_text = response.choices[0].message.content
    summary_text = full_text.split("[ëŒ€ë³¸]")[0].replace("[ìš”ì•½]", "").strip()
    audio_script = full_text.split("[ëŒ€ë³¸]")[1].strip()

    # 6. í†µí•© ì˜¤ë””ì˜¤ íŒŒì¼ëª… ì„¤ì • (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€)
    # nowëŠ” ì•ì—ì„œ ì„œìš¸ ì‹œê°„(Asia/Seoul)ìœ¼ë¡œ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    today_date = now.strftime('%Y%m%d') 
    file_name = f"CV_Daily_Briefing_{today_date}.mp3" 
    full_file_path = os.path.join(audio_dir, file_name)

    audio_response = client.audio.speech.create(
        model="tts-1-hd",
        voice="onyx",
        input=audio_script,
        speed=1
    )
    audio_response.stream_to_file(full_file_path)

    # 7. ë…¸ì…˜ì— ë‹¨ í•˜ë‚˜ì˜ í†µí•© í˜ì´ì§€ ìƒì„±
    audio_url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{GITHUB_REPO}/main/audio/{file_name}"
    
    # ì œëª© í˜•ì‹: [2024-05-20] ì˜¤ëŠ˜ì˜ ë…¼ë¬¸ ë¸Œë¦¬í•‘ (ë…¼ë¬¸ 1 | ë…¼ë¬¸ 2 | ...)
    short_titles = " | ".join([t[:20] + "..." if len(t) > 20 else t for t in paper_titles_list])
    page_title = f"[{now.strftime('%Y-%m-%d')}] í†µí•© ë¸Œë¦¬í•‘ ({len(valid_papers)}ê±´)"

    notion.pages.create(
        parent={"database_id": DATABASE_ID},
        properties={
            "ì´ë¦„": {"title": [{"text": {"content": page_title}}]},
            "ë‚ ì§œ": {"date": {"start": now.date().isoformat()}},
            "ì˜¤ë””ì˜¤": {"url": audio_url}
        },
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {"rich_text": [{"type": "text", "text": {"content": "ğŸ“„ ë…¼ë¬¸ í•µì‹¬ ìš”ì•½"}}]}
            },
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {"rich_text": [{"type": "text", "text": {"content": summary_text}}]}
            }
        ]
    )
    print(f"í†µí•© ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ: {len(valid_papers)}ê°œì˜ ë…¼ë¬¸")

if __name__ == "__main__":
    run_bot()
